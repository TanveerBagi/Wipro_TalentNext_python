#Q1. Sales Prediction
      #Create a model which will predict the sales based on campaigning expenses.
      #Dataset : Advertising.csv  The dataset can be downloaded from https://www.kaggle.com/datasets
      #Perform the following task.
          #Load the data in the DataFrame.
          #Perform Data Preprocessing
          #Handle Categorical Data
          #Perform Exploratory Data Analysis
          #Build the model using Multiple Linear Regression
          #Use the appropriate evaluation metrics
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

df = pd.read_csv("Advertising.csv")

print(df.head())
print(df.info())
print(df.describe())

print(df.isnull().sum())
# if there is categorical data in the dataset
#df = pd.get_dummies(df, drop_first=True)

sns.pairplot(df, x_vars=['TV', 'Radio', 'Newspaper'], y_vars='Sales', height=4, aspect=1, kind='scatter')
plt.show()

corr = df.corr()
sns.heatmap(corr, annot=True, cmap="coolwarm")
plt.show()

X = df[['TV', 'Radio', 'Newspaper']]
y = df['Sales']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

model = LinearRegression()
model.fit(X_train, y_train)

y_pred = model.predict(X_test)

mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_test, y_pred)

print("Mean Squared Error:", mse)
print("Root Mean Squared Error:", rmse)
print("RÂ² Score:", r2)

coef_df = pd.DataFrame(model.coef_, X.columns, columns=['Coefficient'])
print(coef_df)


#Q2. Diabetes Prediction
    #Consider the PIMA Indians diabetes dataset. Create a Model for diabetes prediction based on the features mentioned in the dataset.
    #Dataset : PIMA Indians diabetes dataset. The dataset can be downloaded from https://www.kaggle.com/datasets
    #Perform the following tasks.      
      #Load the data in the DataFrame.      
      #Perform Data Preprocessing      
      #Perform Exploratory Data Analysis      
      #Build the model using Logistic Regression and K-Nearest Neighbour      
      #Use the appropriate evaluation metrics

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

df = pd.read_csv("pima-indians-diabetes.csv")

print(df.head())
print(df.info())
print(df.describe())

print(df.isnull().sum())

cols_with_zero = ["Glucose", "BloodPressure", "SkinThickness", "Insulin", "BMI"]
for col in cols_with_zero:
    df[col] = df[col].replace(0, np.nan)
    df[col].fillna(df[col].median(), inplace=True)

sns.countplot(x="Outcome", data=df)
plt.title("Diabetes Outcome Distribution")
plt.show()

corr = df.corr()
sns.heatmap(corr, annot=True, cmap="coolwarm")
plt.show()

X = df.drop("Outcome", axis=1)
y = df["Outcome"]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

log_reg = LogisticRegression()
log_reg.fit(X_train, y_train)
y_pred_log = log_reg.predict(X_test)

print("Logistic Regression Accuracy:", accuracy_score(y_test, y_pred_log))
print(confusion_matrix(y_test, y_pred_log))
print(classification_report(y_test, y_pred_log))

knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(X_train, y_train)
y_pred_knn = knn.predict(X_test)

print("KNN Accuracy:", accuracy_score(y_test, y_pred_knn))
print(confusion_matrix(y_test, y_pred_knn))
print(classification_report(y_test, y_pred_knn))
